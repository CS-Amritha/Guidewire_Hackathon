{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, BatchNormalization\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['timestamp', 'namespace', 'pod', 'node', 'cpu_usage', 'cpu_limit', 'cpu_request', 'cpu_throttling', 'memory_usage', 'memory_limit', 'memory_request', 'memory_rss', 'network_receive_bytes', 'network_transmit_bytes', 'network_errors', 'restarts', 'oom_killed', 'pod_ready', 'pod_phase', 'disk_read_bytes', 'disk_write_bytes', 'disk_io_errors', 'pod_scheduled', 'pod_pending', 'pod_unschedulable', 'container_running', 'container_terminated', 'container_waiting', 'pod_uptime_seconds', 'cpu_utilization_ratio', 'memory_utilization_ratio', 'CPU Throttling', 'High CPU Usage', 'OOMKilled (Out of Memory)', 'CrashLoopBackOff', 'ContainerNotReady', 'PodUnschedulable', 'NodePressure', 'ImagePullFailure', 'node_cpu_usage', 'node_cpu_capacity', 'node_cpu_allocatable', 'node_cpu_utilization_ratio', 'node_memory_usage', 'node_memory_capacity', 'node_memory_allocatable', 'node_memory_utilization_ratio', 'node_memory_pressure', 'node_disk_read_bytes', 'node_disk_usage', 'node_disk_write_bytes', 'node_disk_pressure', 'node_disk_capacity', 'node_disk_utilization_ratio', 'node_network_receive_bytes', 'node_network_transmit_bytes', 'node_network_errors', 'node_ready', 'node_unschedulable', 'node_out_of_disk', 'node_pods_running', 'node_pods_allocatable', 'node_pods_usage_ratio', 'node_uptime_seconds', 'node_kubelet_healthy', 'node_disk_io_errors', 'node_inode_utilization_ratio', 'node_pid_pressure', 'CPU Pressure', 'Memory Pressure', 'Disk Pressure', 'Network Unavailable', 'Node Not Ready', 'PID Pressure', 'Node Unschedulable', 'deployment_replicas', 'deployment_available_replicas', 'deployment_unavailable_replicas', 'deployment_updated_replicas', 'deployment_mismatch_replicas', 'deployment_cpu_usage', 'deployment_cpu_requests', 'deployment_cpu_limits', 'deployment_cpu_utilization_ratio', 'deployment_memory_usage', 'deployment_memory_requests', 'deployment_memory_limits', 'deployment_memory_utilization_ratio', 'deployment_disk_read_bytes', 'deployment_disk_write_bytes', 'deployment_memory_pressure', 'deployment_disk_pressure', 'deployment_pid_pressure', 'deployment_waiting_pods', 'deployment_age_seconds', 'deployment_unavailable_duration', 'deployment_progressing', 'deployment_available', 'deployment_paused', 'deployment Replica Mismatch', 'deployment Unavailable Pods', 'deployment ImagePullFailure', 'deployment CrashLoopBackOff', 'deployment FailedScheduling', 'deployment QuotaExceeded', 'deployment ProgressDeadlineExceeded', 'deployment']\n",
      "False\n",
      "Dataset loaded successfully.\n",
      "True\n",
      "107\n",
      "cpu-exhaustion-pod                                         25\n",
      "oom-killer-max-5d6b44c9f6-2dct7                            25\n",
      "kube-proxy-2ffwt                                           25\n",
      "kube-controller-manager-chaos-cluster-control-plane        25\n",
      "kube-apiserver-chaos-cluster-control-plane                 25\n",
      "                                                           ..\n",
      "no-matching-node                                           16\n",
      "oom-killer                                                 16\n",
      "container-not-ready-missing-entrypoint-7b46b794bf-rbnql    13\n",
      "image-pull-failure-bbdd569c5-c9jt2                         13\n",
      "private-image-pull-failure-5bd4bbd447-b4b5w                12\n",
      "Name: pod, Length: 115, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from CSV file\n",
    "df = pd.read_csv(\"k8s_pod_metrics.csv\")\n",
    "\n",
    "# Display basic info\n",
    "#print(df.head())  # Preview first few rows\n",
    "#print(df.info())  # Check data types and missing values\n",
    "print(df.columns.to_list())\n",
    "print('pod_errors' in df.columns.to_list())\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(\"deployment\" in df.columns.to_list()) \n",
    "print(len(df.columns.to_list()))\n",
    "print(df['pod'].value_counts()) \n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', dayfirst=True).view('int64') // 10**9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                               None\n",
      "1       default/cpu-throttle-extreme\n",
      "2       default/cpu-throttle-extreme\n",
      "3       default/cpu-throttle-extreme\n",
      "4       default/cpu-throttle-extreme\n",
      "                    ...             \n",
      "2595                            None\n",
      "2596                            None\n",
      "2597                            None\n",
      "2598                            None\n",
      "2599                            None\n",
      "Name: deployment, Length: 2600, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with column mean (for numeric columns)\n",
    "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# Ensure no NaNs remain in any column\n",
    "df.fillna('None', inplace=True)\n",
    "\n",
    "# Replace empty brackets '[]' with zero\n",
    "df.replace('[]', 'None', inplace=True)\n",
    "print(df['deployment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding completed.\n",
      "Remaining object columns: ['disk_read_bytes', 'disk_write_bytes', 'node_cpu_utilization_ratio', 'node_memory_utilization_ratio']\n",
      "[0 1 2 3]\n",
      "[ 10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27\n",
      "  28  29  31  32  39  40  43  44  45  46  47  48  49  86  88  89  90  92\n",
      "  98  99 100 101 102   8   9  50  70  71  72  73  74  75  76  77  78  79\n",
      "  80  81  82  83  84  85   0 105 106 107 108 109 110 111 112 113 114  41\n",
      "  42  51  52  53  54  55  93  94  95  56  57  58  59  60  65  66  67  68\n",
      "  96  87 103   2   3  30  61  62  63  64   1   4   5   6  33  34  35  36\n",
      "  37  38  91  97   7  69 104]\n",
      "[3 2 5 6 4 1 0]\n",
      "[ 0  2  3  4  5  8 10 11 16 18 20 21 22 23 24  9 12 17 13 15  1 14  6  7\n",
      " 19]\n"
     ]
    }
   ],
   "source": [
    "# Define columns to encode\n",
    "categorical_cols = ['namespace', 'pod', 'node', 'deployment']  # Categorical values\n",
    "label_encoders = {}\n",
    "\n",
    "# Apply Label Encoding\n",
    "for col in categorical_cols:\n",
    "    #if col == 'deployment':\n",
    "        #print(df['deployment'])\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    df[col] = label_encoders[col].fit_transform(df[col])\n",
    "\n",
    "print(\"Encoding completed.\")\n",
    "print(\"Remaining object columns:\", df.select_dtypes(include=['object']).columns.tolist())  # Should be empty if all are encoded properly\n",
    "\n",
    "\n",
    "#print(df.head())  # Check if encoding is correct\n",
    "#print(\"Encoding completed. Deployment is now label-encoded like pod and node.\")\n",
    "#print(df['pod'].value_counts()) \n",
    "\n",
    "# debug\n",
    "for i in categorical_cols:\n",
    "    print(df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "df.replace('None', 0, inplace=True)\n",
    "print(len(df.columns.to_list()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: []\n"
     ]
    }
   ],
   "source": [
    "non_numeric_cols = [col for col in df.columns if not np.issubdtype(df[col].dtype, np.number)]\n",
    "print(\"Non-numeric columns:\", non_numeric_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NodePressure', 'QuotaExceeded', 'Network Unavailable', 'CPU Throttling', 'PodUnschedulable', 'Replica Mismatch', 'Node Unschedulable', 'PID Pressure', 'Memory Pressure', 'Disk Pressure', 'ContainerNotReady', 'ImagePullFailure', 'High CPU Usage', 'Node Not Ready', 'OOMKilled (Out of Memory)', 'CPU Pressure', 'ProgressDeadlineExceeded', 'Unavailable Pods', 'FailedScheduling', 'CrashLoopBackOff']\n"
     ]
    }
   ],
   "source": [
    "# Define target columns\n",
    "target_cols = [\n",
    "    'NodePressure', 'QuotaExceeded', 'Network Unavailable', \n",
    "    'CPU Throttling', 'PodUnschedulable', 'Replica Mismatch', \n",
    "    'Node Unschedulable', 'PID Pressure', 'Memory Pressure', \n",
    "    'Disk Pressure', 'ContainerNotReady', 'ImagePullFailure', \n",
    "    'High CPU Usage', 'Node Not Ready', 'OOMKilled (Out of Memory)', \n",
    "    'CPU Pressure', 'ProgressDeadlineExceeded', 'Unavailable Pods', \n",
    "    'FailedScheduling', 'CrashLoopBackOff'\n",
    "]\n",
    " # this is what we are predicting\n",
    "\n",
    "print(target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Debugging: Check unique pod values after changes\n",
    "#print(df['deployment'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature normalization completed. Target labels remain unchanged.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define target columns (binary labels) that should NOT be normalized\n",
    "exclude_time = [    'NodePressure', 'QuotaExceeded', 'Network Unavailable', \n",
    "    'CPU Throttling', 'PodUnschedulable', 'Replica Mismatch', \n",
    "    'Node Unschedulable', 'PID Pressure', 'Memory Pressure', \n",
    "    'Disk Pressure', 'ContainerNotReady', 'ImagePullFailure', \n",
    "    'High CPU Usage', 'Node Not Ready', 'OOMKilled (Out of Memory)', \n",
    "    'CPU Pressure', 'ProgressDeadlineExceeded', 'Unavailable Pods', \n",
    "    'FailedScheduling', 'CrashLoopBackOff', 'timestamp']\n",
    "\n",
    "# Identify feature columns (all columns except target columns)\n",
    "feature_cols = [col for col in df.columns if col not in target_cols + ['timestamp']]\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply MinMax Scaling ONLY to feature columns (excluding target columns)\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "print(\"Feature normalization completed. Target labels remain unchanged.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Window: 2 time steps\n",
      "Prediction Horizon: 2 time steps\n"
     ]
    }
   ],
   "source": [
    "# Define time window (how many past time steps to consider)\n",
    "TIME_WINDOW = 2  # Use past 5 time steps\n",
    "\n",
    "# Define prediction horizon (how far ahead we want to predict)\n",
    "PREDICTION_HORIZON = 2  # Predict 2 time steps into the future\n",
    "\n",
    "print(f\"Time Window: {TIME_WINDOW} time steps\")\n",
    "print(f\"Prediction Horizon: {PREDICTION_HORIZON} time steps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_indices = [i for i in range(len(target_cols))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2140, 2, 106) (samples, time steps, features)\n",
      "y shape: (2140, 20) (samples, target labels)\n",
      "Time-series sequences created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_sequences_per_pod(df, pod_column, target_columns, time_window, prediction_horizon):\n",
    "    \"\"\"\n",
    "    Converts raw time-series data into sequences for training.\n",
    "\n",
    "    - Each sequence contains `time_window` steps of historical data for a specific pod.\n",
    "    - The corresponding label is taken from `prediction_horizon` steps into the future.\n",
    "\n",
    "    Args:\n",
    "    - df: Pandas DataFrame containing the dataset.\n",
    "    - pod_column: The column name representing pod identifiers.\n",
    "    - target_columns: List of column indices corresponding to target labels.\n",
    "    - time_window: Number of past time steps to include in each sequence.\n",
    "    - prediction_horizon: How far ahead to predict.\n",
    "\n",
    "    Returns:\n",
    "    - X (features): NumPy array of shape (samples, time_window, features).\n",
    "    - y (labels): NumPy array of shape (samples, number of target labels).\n",
    "    \"\"\"\n",
    "\n",
    "    X, y = [], []\n",
    "    unique_pods = df[pod_column].unique()  # Get all unique pod names\n",
    "\n",
    "    for pod in unique_pods:\n",
    "        # Extract all rows for the given pod\n",
    "        pod_data = df[df[pod_column] == pod].drop(columns=[pod_column]).values  \n",
    "        num_rows = len(pod_data)\n",
    "        if num_rows < time_window + prediction_horizon:\n",
    "            print(f\"Warning: Pod {pod} has insufficient data and will be skipped.\")\n",
    "            continue\n",
    "\n",
    "        # Ensure we do not go out of bounds\n",
    "        for i in range(num_rows - time_window - prediction_horizon):\n",
    "            # Extract past `time_window` steps as input sequence\n",
    "            input_sequence = pod_data[i:i + time_window]\n",
    "\n",
    "            # Get target values from `prediction_horizon` steps in the future\n",
    "            future_index = i + time_window + prediction_horizon  \n",
    "            target_values = pod_data[future_index, target_columns]  \n",
    "\n",
    "            X.append(input_sequence)\n",
    "            y.append(target_values)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# Generate sequences\n",
    "X, y = create_sequences_per_pod(df, 'pod', target_indices, TIME_WINDOW, PREDICTION_HORIZON)\n",
    "\n",
    "# Print shapes of output arrays\n",
    "print(f\"X shape: {X.shape} (samples, time steps, features)\")\n",
    "print(f\"y shape: {y.shape} (samples, target labels)\")\n",
    "print(\"Time-series sequences created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.74266784e+09 3.33333333e-01 3.33333333e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [1.74266788e+09 3.33333333e-01 3.33333333e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.74266826e+09 0.00000000e+00 6.66666667e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 4.16666667e-01]\n",
      "  [1.74266835e+09 0.00000000e+00 6.66666667e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 4.16666667e-01]]\n",
      "\n",
      " [[1.74266904e+09 0.00000000e+00 8.33333333e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 4.16666667e-02]\n",
      "  [1.74266910e+09 0.00000000e+00 8.33333333e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 4.16666667e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.74266885e+09 3.33333333e-01 8.33333333e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [1.74266892e+09 3.33333333e-01 8.33333333e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.74266860e+09 1.00000000e+00 6.66666667e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 9.16666667e-01]\n",
      "  [1.74266868e+09 1.00000000e+00 6.66666667e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 9.16666667e-01]]\n",
      "\n",
      " [[1.74266904e+09 0.00000000e+00 1.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 7.50000000e-01]\n",
      "  [1.74266910e+09 0.00000000e+00 1.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 7.50000000e-01]]]\n",
      "Training Set: X_train=(1712, 2, 106), y_train=(1712, 20)\n",
      "Testing Set: X_test=(428, 2, 106), y_test=(428, 20)\n",
      "Sequences applied and dataset split successfully.\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "print(X_train)\n",
    "# Print dataset shapes\n",
    "print(f\"Training Set: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"Testing Set: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "print(\"Sequences applied and dataset split successfully.\")\n",
    "#X_train = np.array(X_train, dtype=np.float32)\n",
    "#y_train = np.array(y_train, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_22 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m90,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_23 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m37,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m660\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,380</span> (513.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131,380\u001b[0m (513.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130,996</span> (511.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m130,996\u001b[0m (511.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get input shape\n",
    "n_time_steps = X_train.shape[1]  # TIME_WINDOW (sequence length)\n",
    "n_features = X_train.shape[2]  # Number of input features (metrics)\n",
    "n_outputs = y_train.shape[1]  # Number of target labels \n",
    "\n",
    "# Define the GRU model\n",
    "model = Sequential([\n",
    "    GRU(128, return_sequences=True, input_shape=(n_time_steps, n_features)),  # First GRU layer\n",
    "    Dropout(0.6),  # Prevent overfitting\n",
    "    BatchNormalization(),\n",
    "\n",
    "    GRU(64, return_sequences=False),  # Second GRU layer (returns final output)\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(32, activation='relu'),  # Fully connected layer\n",
    "    Dense(n_outputs, activation='sigmoid')  # Output layer (sigmoid for multi-label classification)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "# Compile the GRU model\n",
    "model.compile(\n",
    "    optimizer='adam',  # Adaptive optimizer for efficient learning\n",
    "    loss='categorical_crossentropy',  # Suitable for multi-label classification\n",
    "    metrics=['accuracy']  # Monitor accuracy during training\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_22 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m90,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_23 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m37,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m660\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,382</span> (513.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131,382\u001b[0m (513.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130,996</span> (511.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m130,996\u001b[0m (511.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save(\"gru_model.h5\")\n",
    "loaded_model = tf.keras.models.load_model(\"gru_model.h5\")\n",
    "\n",
    "# Check model summary\n",
    "loaded_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.1408 - loss: 4925079040.0000 - val_accuracy: 1.0000 - val_loss: 2997897472.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8197 - loss: 1738791168.0000 - val_accuracy: 1.0000 - val_loss: 1014638528.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9702 - loss: 424575552.0000 - val_accuracy: 1.0000 - val_loss: 120766528.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 49184212.0000 - val_accuracy: 1.0000 - val_loss: 78137.2500\n",
      "Epoch 5/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9677951.0000 - val_accuracy: 1.0000 - val_loss: 2327.2957\n",
      "Epoch 6/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1063664.2500 - val_accuracy: 1.0000 - val_loss: 121.5202\n",
      "Epoch 7/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 19633.2793 - val_accuracy: 1.0000 - val_loss: 116.9680\n",
      "Epoch 8/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8653.4873 - val_accuracy: 1.0000 - val_loss: 284.7762\n",
      "Epoch 9/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6297.4600 - val_accuracy: 1.0000 - val_loss: 263.9111\n",
      "Epoch 10/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1892.3379 - val_accuracy: 1.0000 - val_loss: 467.8419\n",
      "Epoch 11/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1315.4875 - val_accuracy: 1.0000 - val_loss: 593.3632\n",
      "Epoch 12/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 765.5577 - val_accuracy: 1.0000 - val_loss: 724.4122\n",
      "Epoch 13/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 676.6819 - val_accuracy: 1.0000 - val_loss: 789.4612\n",
      "Epoch 14/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 723.7980 - val_accuracy: 1.0000 - val_loss: 962.1301\n",
      "Epoch 15/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 992.5720 - val_accuracy: 1.0000 - val_loss: 1183.4897\n",
      "Epoch 16/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1064.9436 - val_accuracy: 1.0000 - val_loss: 1265.5680\n",
      "Epoch 17/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1253.1819 - val_accuracy: 1.0000 - val_loss: 1518.4524\n",
      "Epoch 18/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1445.4840 - val_accuracy: 1.0000 - val_loss: 1629.9452\n",
      "Epoch 19/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1715.6180 - val_accuracy: 1.0000 - val_loss: 1948.3165\n",
      "Epoch 20/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1966.6598 - val_accuracy: 1.0000 - val_loss: 2132.3867\n",
      "Epoch 21/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2076.3108 - val_accuracy: 1.0000 - val_loss: 2404.2236\n",
      "Epoch 22/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2434.7390 - val_accuracy: 1.0000 - val_loss: 2505.5330\n",
      "Epoch 23/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2725.3245 - val_accuracy: 1.0000 - val_loss: 2787.9849\n",
      "Epoch 24/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3280.0017 - val_accuracy: 1.0000 - val_loss: 3260.3618\n",
      "Epoch 25/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3373.8254 - val_accuracy: 1.0000 - val_loss: 3769.5132\n",
      "Epoch 26/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3759.9324 - val_accuracy: 1.0000 - val_loss: 4196.1274\n",
      "Epoch 27/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4272.3071 - val_accuracy: 1.0000 - val_loss: 4831.1641\n",
      "Epoch 28/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4671.1646 - val_accuracy: 1.0000 - val_loss: 5223.4639\n",
      "Epoch 29/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5188.2446 - val_accuracy: 1.0000 - val_loss: 5276.0977\n",
      "Epoch 30/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5727.0938 - val_accuracy: 1.0000 - val_loss: 6200.4707\n",
      "Epoch 31/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5986.5371 - val_accuracy: 1.0000 - val_loss: 6802.1846\n",
      "Epoch 32/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6363.0137 - val_accuracy: 1.0000 - val_loss: 7623.9756\n",
      "Epoch 33/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6976.7402 - val_accuracy: 1.0000 - val_loss: 7852.8521\n",
      "Epoch 34/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7507.3862 - val_accuracy: 1.0000 - val_loss: 9008.1787\n",
      "Epoch 35/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7915.4678 - val_accuracy: 1.0000 - val_loss: 9371.7646\n",
      "Epoch 36/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8896.2197 - val_accuracy: 1.0000 - val_loss: 10192.4189\n",
      "Epoch 37/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9717.3301 - val_accuracy: 1.0000 - val_loss: 10851.9678\n",
      "Epoch 38/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9831.6074 - val_accuracy: 1.0000 - val_loss: 12206.3750\n",
      "Epoch 39/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 10853.4814 - val_accuracy: 1.0000 - val_loss: 12071.4023\n",
      "Epoch 40/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 11332.8066 - val_accuracy: 1.0000 - val_loss: 13175.1406\n",
      "Epoch 41/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 12148.0225 - val_accuracy: 1.0000 - val_loss: 14245.3262\n",
      "Epoch 42/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 12819.4121 - val_accuracy: 1.0000 - val_loss: 15119.0283\n",
      "Epoch 43/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 13875.5010 - val_accuracy: 1.0000 - val_loss: 16227.2520\n",
      "Epoch 44/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 14350.4453 - val_accuracy: 1.0000 - val_loss: 17460.3340\n",
      "Epoch 45/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 15608.7539 - val_accuracy: 1.0000 - val_loss: 17525.3242\n",
      "Epoch 46/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 15800.0527 - val_accuracy: 1.0000 - val_loss: 18458.1270\n",
      "Epoch 47/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 18143.9082 - val_accuracy: 1.0000 - val_loss: 20280.5117\n",
      "Epoch 48/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 18584.4922 - val_accuracy: 1.0000 - val_loss: 21373.8887\n",
      "Epoch 49/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 19267.3965 - val_accuracy: 1.0000 - val_loss: 22130.4570\n",
      "Epoch 50/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 19452.1621 - val_accuracy: 1.0000 - val_loss: 23708.0625\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define batch size and epochs\n",
    "BATCH_SIZE = 32  # Number of samples per batch\n",
    "EPOCHS = 50  # Number of training iterations\n",
    "\n",
    "# Ensure all data is numeric before conversion\n",
    "# Example: If X_train contains non-numeric data, preprocess it here\n",
    "# X_train = preprocess_features(X_train)\n",
    "\n",
    "# Convert training and test sets to float32\n",
    "X_train = np.array(X_train).astype(np.float32)\n",
    "X_test = np.array(X_test).astype(np.float32)\n",
    "y_train = np.array(y_train).astype(np.float32)\n",
    "y_test = np.array(y_test).astype(np.float32)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,  # Training data\n",
    "    validation_data=(X_test, y_test),  # Validation during training\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1  # Print training progress\n",
    ")\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 21724.1484 \n",
      "Test Loss: 23708.0625\n",
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
